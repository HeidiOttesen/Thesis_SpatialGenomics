---
title: "KNN testing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(spdep)
```





#Let's make some sample data so people can run it. First a matrix of point coordinates:
```{r}
#coords <- cbind(runif(100), runif(100)) # Example code

#coords <- cbind(ctmp[,2],ctmp[,1])
#coords <- coords[1:sub, ]
```




#Then suppose we have A measured at each of the 100 points:
# counts / weights to each coordinate:


#And some ID values which we might need:

#Then we compute the nearest neighbours (I'm doing 5 nearest for simplicity):
#Each element of knn50 is a vector of the index in coords of the neighbours:
```{r}
#A <- runif(100)
A <- ctmp[,3]
a <- A[1:sub]
#IDs = paste0("ID-",1:100)
#IDs <- 

```



So for example we can plot all the points, plot the neighbours of point 5 in green, then point 5 itself in red:
  
Then if we want to average over some measure at each of those points, here A, we can use sapply and a function that subsets from A according to those nearest elements:


giving the mean of A for the 5 nearest neighbours of each of the 100 points. Note the A value of the point itself isn't included.

## Visualize single dots:

```{r}

plot(coords)
points(coords[knn50[[5]],],col="green",pch=19)
points(coords[5,,drop=FALSE],col="red",pch=19)
sapply(1:length(knn50), function(N){mean(A[N])}) #What is this?! - Applying weights/counts to the dots? 
```



https://github.com/patrickCNMartin/VesaliusDev/blob/main/R/embeddings.R


```{r}
library("dbscan")
ctmp.knn <- kNN(coords, k = 5)
```

## Collecting data:

Barcodes and coordinates from bead_locations



```{r}
alias <- "mouse_liver_met_2_dna_200114_10"
in.path <- "~/Thesis_SpatialGenomics/SlideSeq/SlideSeq_ves_test/"
out.path <- "~/Thesis_SpatialGenomics/R_Output/"
bead <- ReadSlideSeq(paste0(in.path, alias, ".bead_locations.csv"))
#1. create a vector that contains all your barcodes.
barcodes <- rownames(bead@coordinates)
bead.coords <- bead@coordinates
coords <- cbind(bead.coords$xcoord, bead.coords$ycoord)

k <- 5
l <- length(barcodes)

ctmp.knearneigh <- knearneigh(coords, k = k)

knn50 <- knn2nb(ctmp.knearneigh, row.names = barcodes)
ctmp.nn <- ctmp.knearneigh$nn

knn50[[1]]




```

One way to think about the pooling algorithm is:
Get all the nearest neighbours for each set of coordinates (essentially Knn) associated to each barcode
1. create a vector that contains all your barcodes.



Patrick's code:
"the nearest neighbour index (nn in the first one and id in the second one) you can use that to get the barcode name (what ever each bin is called) and then group that into g number of groups."
Distance pooling array
https://github.com/patrickCNMartin/Vesalius/blob/3567500a00d5baff9274cb8e153622c5f84e15c8/R/IsolatingTerritories.R#L736-L873

.distancePooling.array <- function(img,captureRadius,minBar){

## Get knn groups of barcodes (from knn)
I don't know how to keep only unique barcodes
the length of the list should be the length / k - but I still have the full length number of groups..

There are also 14 leftovers not in any group If I understand correctly?

## Unique barcode knn list
2. Create an empty list that will grow as you assign more groups to it.
3. Take one random barcode from your barcode vector ( you can also just take the first 1 in the list) and all of its neighbours and put them in the list.
4. Remove those barcodes from your barcodes vector.
5. Repeat step 4 and 5 until all barcodes have been assigned into your list.

```{r}
knn5 <- knn50[1:l] #Just the grouped indexes (to the barcodes) - not the other attributes

bc <- barcodes
knn5.bc <- vector(mode="list", length=l) #holds unique barcodes in groups of up to k
doubles <- vector(mode="list", length=l) #Probably don't need this..
knn5.bc1 <- vector(mode="list", length=l) #unique again but without NA elements (Still null groups)

i <- 1

while(i <= l){
  j <- 1
  while(j <= k){
    ix <- knn5[[i]][j]
    b <- barcodes[ix]
    if(b %in% bc){
      knn5.bc[[i]][j] <- b
    }else{
      doubles[[i]][j] <- b
    }
    j <- j + 1
    bc <- bc[!bc %in% b]
  }
  x <- knn5.bc[[i]]
  knn5.bc1[[i]] <- x[!is.na(x)]
  i <- i + 1
}

length(bc) #leftovers

```



6. take the median x and y coordinates of all barcodes present in each group and create a new coordinate file with a new set of barcode names

```{r}
bead.x <- data.frame(bead.coords$xcoord)
bead.y <- data.frame(bead.coords$ycoord)

rownames(bead.x) <- rownames(bead@coordinates)
rownames(bead.y) <- rownames(bead@coordinates)

l <- length(knn5.bc1)
bc.g <- vector(length=l)
knn.x <- vector(length=l)
knn.y <- vector(length=l)
i <- 1

while(i <= l){
  lth <- length(knn5.bc1[[i]])
  x <- vector(length=lth)
  y <- vector(length=lth)
  j <- 1
  while(j <= lth){
    b <- knn5.bc1[[i]][j]
    x[[j]] <- bead.x[b, ]
    y[[j]] <- bead.y[b, ]
    j <- j + 1
  }
  if(length(knn5.bc1[[i]]) > 0){
    bc.g[[i]] <- knn5.bc1[[i]][1]
  }
  knn.x[[i]] <- median(x)
  knn.y[[i]] <- median(y)
  i <- i + 1
}
#knn.x %>% drop_na()
#knn.y %>% drop_na()

#knn5.bc1[[i]] <- x[!is.na(x)]

comb <- cbind(knn.x, knn.y)
as.data.frame(comb)

rownames(comb) <- bc.g

row.has.na <- apply(comb, 1, function(x){any(is.na(x))})
sum(row.has.na) #number of rows with na's to be removed
comb.filtered <- comb[!row.has.na,]


```

## Remove empty groups from list
knn.bc - New list is same length as comb.filtered

```{r}
filt.l <- length(comb.filtered[,1])
knn.bc <- vector(mode="list", length=filt.l) #unique + no NAs + no empty groups
i <- 1

while(i <= filt.l){
  x <- knn5.bc1[[i]]
  if(length(x)){
    knn.bc[[i]] <- x
  }
  i <- i + 1
}
```

Once you have this list, you will combine all the counts associated to each group.
8. Create empty list of length equal to the group list
9. Loop through your group list and extract all columns in your count matrix associated with the barcodes in each group
10. Add counts together. Essentially RowSums for all columns youâ€™ve just extracted. The bins stay the same so you sum over rows.


## Summing counts over knn-groups:
df - Sparse matrix vector from the DNA vesalius script - Barcodes as columns, bins as rows.
rowSums - doesn't work on groups with just 1 barcode.. 


- Iterate over knn groups 
- take the counts for those barcodes for all bins from the sparsematrix
- Sum the counts for each group and each bin 

```{r}
# knn.bc <- knn5.bc1[!is.null(knn5.bc1)] ## Doesn't work still have null groups in my list.

spMtrx <- df
i <- 1
l <- length(knn.bc)
grMtrx <- matrix(0, nrow = nrow(spMtrx), ncol = l)



while(i <= l){
  tmp <- knn.bc[[i]]
  t <- spMtrx[,tmp]
  ltmp <- length(tmp)
  if(ltmp > 1){
    grMtrx[,i] <- rowSums(t)
  }else if(ltmp == 1){
    grMtrx[,i] <- t
  }
  i <- i + 1 
}




```

# Rename columns with my new barcode names

- The first member barcode ID represents the group - stored in vector bc.g
- Same barcodes as used as rownames in vector "comb"


11. Rename the columns in your count matrix to reflect you new barcode names

```{r}
colnames(grMtrx) <- bc.g
```



```{r}

bc <- barcodes
tmp <- data.frame()
ls <- list()
i <- 1
while(length(bc) >0){
  pool <- sample(bc,1)
  res <- lapply(knn, function(ch) grep("a", ch))
  converge <- FALSE
  while(!converge){
    #------------------------------------------------------------------#
    # This while loop checks if all possible barcodes have been pooled
    # into the current territory
    #------------------------------------------------------------------#
    if(length(inter)==1){
      #------------------------------------------------------------#
      # when there is only one barcodes
      # remove barcode from pool and move on
      #------------------------------------------------------------#
      ls[[i]] <- pool
      barcodes <- barcodes[!barcodes %in% pool]
      i <- i + 1
      converge <- TRUE
    }
  }
}

```
 else {
      #------------------------------------------------------------#
      # Get a new pool from the distance matrix
      # and check which ones are within capture radius
      #------------------------------------------------------------#
      newPool <- distanceMatrix[,inter] # 1 dimension with distances to current inter-barcode
      
      newPool <- unique(unlist(lapply(seq_len(ncol(newPool)),
                                      function(idx,np,captureRadius){
                                        
                                        res <- rownames(np)[np[,idx] <=
                                                              captureRadius]
                                        return(res)
                                      },newPool,captureRadius)))
      #------------------------------------------------------------#
      # check which barcodes in the new pool overlap with
      # the ones in the full pool
      # If there is a perfect overlap then there are no new bacodes
      # to pool into a territory
      #------------------------------------------------------------#
      overlap <- newPool %in% pool
      
      if(sum(overlap) != length(newPool)){
        #------------------------------------------------------#
        # There are still some new barcodes to pool
        # lets do some more looping then
                        #------------------------------------------------------#
                        pool <- unique(c(pool,newPool[!overlap]))
                        inter <- unique(newPool[!overlap])
                  } else {
                        #------------------------------------------------------#
                        # it is done ! no more barcodes for this territory
                        #------------------------------------------------------#
                        territories[[count]] <- pool
                        count <- count +1
                        barcodes <- barcodes[!barcodes %in% pool]

                        converge <- TRUE

                  }
              }
          }
      }
    #--------------------------------------------------------------------------#
    # Clean up drop outs
    #--------------------------------------------------------------------------#

      allTers <- img$territory

      for(ter in seq_along(territories)){
            loc <- img$barcodes %in% territories[[ter]]
            if(length(territories[[ter]]) <= minBar){
               allTers[loc] <- "isolated"
            } else {
               allTers[loc] <- ter
            }



      }
      return(allTers)
}

Patrick
Reduce tensor Resolution
https://github.com/patrickCNMartin/VesaliusDev/blob/main/R/embeddings.R


```{r}
.reduceTensorResolution <- function(coordinates,tensorResolution = 1){
  #----------------------------------------------------------------------------#
  # we will reduce number of points this way
  # this should keep all barcodes - with overlapping coordinates
  #----------------------------------------------------------------------------#
  coordinates$x <- round(coordinates$x * tensorResolution)
  coordinates$y <- round(coordinates$y * tensorResolution)
  #----------------------------------------------------------------------------#
  # Now we get coordinate tags - we use this to find all the merge locations
  # sorting and using rle to ensure that we actually merge them
  #----------------------------------------------------------------------------#
  tag <- paste0(coordinates$x,"_",coordinates$y)

  locs <- rle(sort(tag))
  dup <- locs$values[which(locs$length >1)]
  #----------------------------------------------------------------------------#
  # creating new merged labels
  #----------------------------------------------------------------------------#
  dupTags <- lapply(dup,function(dup,tag,barcodes){
    tmpLocs <- which(tag == dup)
    barcodes<- paste0(barcodes[tmpLocs],sep ="_et_", collapse ="")
    barcodes <- rep(barcodes,times = length(tmpLocs))
    return(barcodes)
  },tag = tag,barcodes = coordinates$barcodes)
  #----------------------------------------------------------------------------#
  # assigning new merged barcodes
  # for some reason match doesn't seem to work here - it only returns one of the
  # values
  #----------------------------------------------------------------------------#
  locs <- unlist(lapply(dup, function(dup,tag){
      return(which(tag == dup))
  },tag = tag))
  coordinates$barcodes[locs] <- unlist(dupTags)
  coordinates <- coordinates %>% distinct(barcodes,.keep_all = TRUE)
  return(coordinates)
}
```



Patrick 
Adjust counts:
https://github.com/patrickCNMartin/VesaliusDev/blob/main/R/embeddings.R

```{r}
#.adjustCounts <- function(coordinates, counts,cores = 1){
    #--------------------------------------------------------------------------#
    # First get all barcode names and compare which ones are missing
    #--------------------------------------------------------------------------#
coordBar <- unique(coordinates$barcodes)
countBar <- unique(colnames(counts))
concat <- sapply(strsplit(coordBar,"_et_"),length) > 1
coordBar <- coordBar[concat]
countBar <- countBar[!concat]

    #--------------------------------------------------------------------------#
    # next we merge counts together when barcodes have been merged
    #--------------------------------------------------------------------------#
    tmpBar <- strsplit(coordBar,"_et_")

    empty <- parallel::mclapply(tmpBar, function(coord,count){
        tmp <- rowSums(count[,coord])
        return(tmp)
    },count = counts, mc.cores = cores)

    empty <- do.call("cbind",empty)

    colnames(empty) <- coordBar

    merged <- cbind(counts[,countBar],empty)
    return(merged)
}
```

